{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a3352c55-74f5-4627-bffe-2a62646b9ca8",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "5f56ae059e60c644d20fcf6566e83bde",
     "grade": false,
     "grade_id": "cell-e7f749f1d24233da",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "# IS319 - Deep Learning\n",
    "\n",
    "## TP1 - Neural networks\n",
    "\n",
    "The goal of this TP is to implement a simple feedforward neural network, but without the use of libraries like PyTorch or TensorFlow. We will only use NumPy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0a45a5ac-e124-4dd4-8c70-162cf1f303f7",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f27823f73c40d5370ea21b4664de6d15",
     "grade": false,
     "grade_id": "cell-00063860a6102415",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b494d22-a981-4cef-9a2f-180e2c03463c",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "0fc7cdf13386929f1036ad16e37e9bb7",
     "grade": false,
     "grade_id": "cell-6677b191d92dc6b1",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "### 1. Activation function and its derivative\n",
    "\n",
    "**(Question)** Implement the following activation function and its respective gradient (vector of partial derivatives). These should be applied element-wise to the input vector `a`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "977beeb6-6308-4a62-a6ec-cd5d7ef4f0af",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b450d1ed2934af7ada438471a86d694b",
     "grade": false,
     "grade_id": "cell-24345ebc30158580",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def sigmoid(a):\n",
    "    '''Return the element-wise sigmoid of the input vector.'''\n",
    "    return 1/(1+np.exp(-a))\n",
    "\n",
    "def d_sigmoid(a):\n",
    "    '''Return the partial derivatives of the sigmoid function\n",
    "    with respect to the input vector.'''\n",
    "    return np.multiply(sigmoid(a),(np.ones_like(sigmoid(a)) - sigmoid(a)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d135483f-3b82-44f3-b7be-469e71de5e42",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "560266600065160cb781c5aca7376630",
     "grade": true,
     "grade_id": "activation-functions",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "a = np.random.randn(100)\n",
    "assert np.all(sigmoid(a) >= 0.)\n",
    "assert np.all(sigmoid(a) <= 1.)\n",
    "assert sigmoid(0.) == 0.5\n",
    "assert np.all(d_sigmoid(a) >= 0.)\n",
    "assert np.all(d_sigmoid(a) <= 0.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2496f14-4f65-45aa-81de-7ed6776512f3",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "964d4939bd557cbe58eec84c4f663b6c",
     "grade": false,
     "grade_id": "cell-b5b0c0c62db57fb8",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### 2. Loss function and its derivative"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e43e836c-55d0-47c7-a66a-9eadd6e808e2",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "338407dbc743f6cc63b292b769db9dc2",
     "grade": false,
     "grade_id": "cell-cf207a1a25ede0bf",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "**(Question)** Implement the following loss function and its respective gradient (vector of partial derivatives).\n",
    "\n",
    "`y` and `d` correspond to predictions and ground-truth labels respectively. They are assumed to be be matrices of size `n_classes * n_samples`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f765ff51-e5f0-4639-bf94-b73ea1a4d729",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9e354857200a6959d1c84a85536a5fe4",
     "grade": false,
     "grade_id": "cell-0570574f9ec3aec5",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def squared_error(y, d):\n",
    "    '''Return a scalar corresponding to the sum of squared errors.'''\n",
    "    # The sum instead of mean will be more convenient for this TP\n",
    "    return 0.5*np.sum(np.power(y-d, 2))\n",
    "def d_squared_error(y, d):\n",
    "    '''Return the vector of partial derivatives of the sum of\n",
    "    squared errors with respect to the predictions.'''\n",
    "    return y-d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "83c7a3fc-c76f-4d24-afca-25c409a8aff9",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ba56624405c27c0d63ad4f7591d6d1ae",
     "grade": true,
     "grade_id": "loss-function",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "y = np.random.randn(3, 100)\n",
    "d = np.random.randn(3, 100)\n",
    "assert squared_error(y, d) >= 0.\n",
    "assert d_squared_error(y, d).shape == y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4dfe238-cce1-447f-bc74-c92e2faff4b3",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "982d82edc67b00fc3f6a4478615ffca8",
     "grade": false,
     "grade_id": "cell-f5669aa56560f23f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "### 3. Neural network architecture\n",
    "\n",
    "We will implement a simple fully-connected neural network with **one hidden layer** and **one output layer**.\n",
    "\n",
    "This neural network is defined by a number of inputs, a number of hidden units, and a number of output units.\n",
    "\n",
    "The activation function will be sigmoid and the loss function will be the sum of squared errors, both implemented above.\n",
    "\n",
    "**(Question)** Complete the class below to initialize the weights and biases randomly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "34b35e8b-ca06-4e03-9121-5d012b89b40d",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "682df5cc19b5bdfca32a46530e75b515",
     "grade": false,
     "grade_id": "cell-4ae365acb7330ae3",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class NeuralNetwork():\n",
    "    def __init__(self, n_input, n_hidden, n_output):\n",
    "        '''Initialize a neural network with `n_input` input neurons,\n",
    "        `n_hidden` hidden neurons and `n_output` output neurons.'''\n",
    "        self.n_input = n_input\n",
    "        self.n_hidden = n_hidden\n",
    "        self.n_output = n_output\n",
    "        self.init_weights()\n",
    "        \n",
    "    def init_weights(self):\n",
    "        '''Initialize random weights with attributes `W1`, `b1`, `W2` and `b2`.'''\n",
    "        self.W1 = np.random.rand(self.n_hidden, self.n_input)\n",
    "        self.b1 = np.random.rand(self.n_hidden, 1)\n",
    "        self.W2 = np.random.rand(self.n_output, self.n_hidden)\n",
    "        self.b2 = np.random.rand(self.n_output, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "98ee2249-0ffe-45b9-84aa-43df08dc2ffe",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "58074da67660f7a263cf4a5a217cdbc9",
     "grade": true,
     "grade_id": "init-weights",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "nn = NeuralNetwork(64, 32, 3)\n",
    "assert nn.W1.ndim == 2\n",
    "assert nn.b1.ndim == 2\n",
    "assert nn.W2.ndim == 2\n",
    "assert nn.b2.ndim == 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36dd53bb-9867-436a-ba06-f12ab5c6ecb9",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e06363c60f3126a75881e357a54291b4",
     "grade": false,
     "grade_id": "cell-b38df17eaae875f5",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "### 4. Forward pass\n",
    "\n",
    "The forward pass is defined as:\n",
    "$$\\begin{align*}\n",
    "\\mathbf{h}_1 &= \\sigma(\\mathbf{a}_1) \\quad\\text{with}\\quad \\mathbf{a}_1 = \\mathbf{W}_1 \\mathbf{x} + \\mathbf{b}_1 \\\\\n",
    "\\mathbf{y} &= \\sigma(\\mathbf{a}_2) \\quad\\text{with}\\quad \\mathbf{a}_2 = \\mathbf{W}_2 \\mathbf{h}_1 + \\mathbf{b}_2\n",
    "\\end{align*}$$\n",
    "\n",
    "**(Question)** Implement the forward pass for input examples `X`. Save intermediate results `a1`, `h1` and `a2` into attributes (as they will be needed for the backpropagation algorithm)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0a17e7b8-f65d-46c5-8dbf-beaa9ae108e1",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5184d383ebc7f26abfd5b14931a7a9d9",
     "grade": false,
     "grade_id": "cell-ec6cc8adc2e96480",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class NeuralNetwork(NeuralNetwork): # (the method will be added to the `NeuralNetwork` class)\n",
    "    def forward(self, X):\n",
    "        self.a1 = self.W1@X + self.b1\n",
    "        self.h1 = sigmoid(self.a1)\n",
    "        self.a2 = self.W2@self.h1 + self.b2\n",
    "        return sigmoid(self.a2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a4ebfecd-ccf7-4d54-a817-7a8418733511",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "fda0d7850901a8f80e7f34f12f1f0488",
     "grade": true,
     "grade_id": "forward-pass",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "nn = NeuralNetwork(64, 32, 3)\n",
    "X = np.random.randn(64, 100)\n",
    "y = nn.forward(X)\n",
    "assert y.shape == (3, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0776cbe4-c4dc-4022-bbb6-7a72ea9cd33f",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "512aeaf857d711af6f945c86d86507db",
     "grade": false,
     "grade_id": "cell-a74aac18b5d769d3",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "**(Question)** Implement the function below to obtain a classification decision from the network. To do that, apply the forward pass, then choose the class corresponding to the maximum output value.\n",
    "\n",
    "*Hint:* use the `np.argmax` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "51c63f4d-c588-4f53-a491-04b771a748ec",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ceeb137463653213aa3a97d6cae7a073",
     "grade": false,
     "grade_id": "cell-07e51093c0c43eef",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class NeuralNetwork(NeuralNetwork): # (the method will be added to the `NeuralNetwork` class)\n",
    "    def predict(self, X):\n",
    "        return np.argmax(self.forward(X), axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "24649afc-05ba-458d-b221-65faf4708579",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1423d9148c0abdf24e6bb3d5f27f4b63",
     "grade": true,
     "grade_id": "predict",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "nn = NeuralNetwork(64, 32, 3)\n",
    "X = np.random.randn(64, 100)\n",
    "y = nn.predict(X)\n",
    "assert y.shape == (100,)\n",
    "assert np.any(y == 0) or np.any(y == 1) or np.any(y == 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9da06ec3-f507-4fff-8083-fee28c07f227",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "10b0b1144dcc813fa37b813c6ae7ab05",
     "grade": false,
     "grade_id": "cell-716664c03ec25271",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "### 5. Backward pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "810de3e4-4745-429d-b413-1fcd01ab78b4",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ccb60940c6bf98203d784a85f79252e6",
     "grade": false,
     "grade_id": "cell-a379bc9c9644efe2",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "**(Question)** Implement the backward pass for input examples `X`, ground-truth `d`, predictions `y`.\n",
    "\n",
    "*Advice:* keep track of the shapes of each derivative using comments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2b0baa1a-0693-42d6-acb6-af801ddd3b38",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c10bb98310ab5ee3faa32b668caa4d0d",
     "grade": false,
     "grade_id": "cell-dc848db6c6a52963",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class NeuralNetwork(NeuralNetwork):\n",
    "    def backward(self, X, y, d):\n",
    "        '''Compute the partial derivatives of the loss function\n",
    "        with respect to all weights of the neural network.\n",
    "        Return these in variables `d_W1`, `d_b1`, `d_W2` and `d_b2`.'''\n",
    "        # Backpropagation for the output layer\n",
    "        # You should compute, d_ey, d_ya2, d_a2w2 and finally delta2\n",
    "        # Then you can compute d_W2 and d_b2\n",
    "        d_ey = d_squared_error(y, d)\n",
    "        d_ya2 = d_sigmoid(self.a2)\n",
    "        d_a2w2 = self.h1\n",
    "        delta2 = np.multiply(d_ey, d_ya2)\n",
    "        d_W2 = delta2@d_a2w2.T\n",
    "        d_b2 = np.sum(delta2, axis=1, keepdims=True)\n",
    "\n",
    "        \n",
    "        # Backpropagation for the hidden layer\n",
    "        # You should comput d_h1a1 and finally delta1\n",
    "        # Then you can compute d_W1 and d_b1\n",
    "        d_h1a1 = d_sigmoid(self.a1)\n",
    "        d_a1w1 = X\n",
    "        delta1 = np.multiply(self.W2.T@delta2, d_h1a1)\n",
    "        d_W1 = delta1@d_a1w1.T\n",
    "        d_b1 = np.sum(delta1, axis=1, keepdims=True)\n",
    "\n",
    "        \n",
    "        return d_W1, d_b1, d_W2, d_b2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d48b45f8-e1ad-4995-b0f7-ebf2f4a5af1f",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "43dacaabd4b1f99cecd67d48bc087b68",
     "grade": true,
     "grade_id": "backward",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "nn = NeuralNetwork(64, 32, 3)\n",
    "X = np.random.randn(64, 100)\n",
    "d = np.random.randint(0, 2, size=(3, 100))\n",
    "y = nn.forward(X)\n",
    "loss = squared_error(y, d)\n",
    "d_W1, d_b1, d_W2, d_b2 = nn.backward(X, y, d)\n",
    "assert d_W1.shape == nn.W1.shape\n",
    "assert d_b1.shape == nn.b1.shape\n",
    "assert d_W2.shape == nn.W2.shape\n",
    "assert d_b2.shape == nn.b2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f24a0eb-ef0d-4de5-991e-07d6bf058af5",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "0923b4500a605d7dfc5b4d58460af318",
     "grade": false,
     "grade_id": "cell-0f7f2ccc7c2703a8",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "### 6. Weights update with gradient descent\n",
    "\n",
    "**(Question)** Complete the following code to implement one iteration of the training process:\n",
    "- Apply the forward pass on training data and compute the loss\n",
    "- Apply backpropagation to compute the gradient of the loss with respect to the network parameters\n",
    "- Apply gradient descent to update the network parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "afbfeefb-6232-4b1a-9662-2db27ee41321",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "bd517e2969c8ef56d55535f60e75448e",
     "grade": false,
     "grade_id": "cell-064008dd04d210c7",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class NeuralNetwork(NeuralNetwork):\n",
    "    def train_iteration(self, X, d, lr=1e-2):\n",
    "        # Apply forward pass and compute the loss\n",
    "        y = self.forward(X)\n",
    "        loss = squared_error(y, d)\n",
    "        # Apply backpropagation to compute the gradients\n",
    "        d_W1, d_b1, d_W2, d_b2 = self.backward(X, y, d)\n",
    "           \n",
    "        # Apply gradient descent to update the weights\n",
    "        # YOUR CODE HERE\n",
    "        self.W1 = self.W1 - lr*d_W1\n",
    "        self.b1 = self.b1 - lr*d_b1\n",
    "        self.W2 = self.W2 - lr*d_W2\n",
    "        self.b2 = self.b2 - lr*d_b2 \n",
    "        loss = squared_error(y, d)\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9e69d878-5a2e-457d-b0ad-76f2915909a4",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5c986a85fe63184deffcf06225b1a750",
     "grade": true,
     "grade_id": "train-iteration",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "nn = NeuralNetwork(64, 32, 3)\n",
    "X = np.random.randn(64, 100)\n",
    "d = np.random.randint(0, 2, size=(3, 100))\n",
    "loss = nn.train_iteration(X, d, lr=100)\n",
    "assert loss >= 0."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "375846fe-7894-4467-9245-ce02b845d587",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "2be8e2aac2709ddb02ba084c50bf7ff4",
     "grade": false,
     "grade_id": "cell-f6f5fa4a0e6feedc",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "### 7. Mini-batch training loop\n",
    "\n",
    "Now, we will implement the main training loop of our neural network.\n",
    "\n",
    "We will use stochastic gradient descent with mini-batch: the weights will be updated by performing gradient descent on shuffled subsets of training data.\n",
    "\n",
    "We will train the network for a number of epochs (an epoch is performed when the whole training set has been used with this mini-batch procedure).\n",
    "\n",
    "**(Question)** Complete the code below to implement the training loop with minibatch stochastic gradient descent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "130674e9-0101-4192-baf0-312abdbd0134",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "93c2d09dd8e052523c7de23ad4901c12",
     "grade": false,
     "grade_id": "cell-d38adca6962df05a",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class NeuralNetwork(NeuralNetwork):\n",
    "    def fit(self, X, d, batch_size, n_epochs=10, lr=1e-2):\n",
    "        n_samples = X.shape[1]\n",
    "        n_batches = (n_samples // batch_size) + 1\n",
    "        epoch_loss = 0.\n",
    "        for e in range(n_epochs):\n",
    "            # Shuffle dataset\n",
    "            permutation = np.random.permutation(n_samples)\n",
    "            X, d = X[:, permutation], d[:, permutation]\n",
    "            # Loop over each batch\n",
    "            for b in range(0, n_samples, batch_size): # range(start, stop, step)\n",
    "                # Grab the current batch in `X_batch` and `d_batch`\n",
    "                X_batch = X[b,b+batch_size]\n",
    "                d_batch = d[b,b+batch_size]\n",
    "                # Apply training iteration and update epoch loss\n",
    "                epoch_loss += self.train_iteration(X_batch, d_batch, lr)\n",
    "            # Compute average epoch loss and print it\n",
    "            print(f\"Epoch loss: {epoch_loss/n_epochs}\")\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2116cae8-1f48-45a4-b1d7-bf5cd35e97d4",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "310cefcc668c25ded2cfc87b04cf2434",
     "grade": false,
     "grade_id": "cell-c980fa7b2fa057b9",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "### 8. Train the network on the MNIST dataset\n",
    "\n",
    "The MNIST dataset is composed of 70000 greyscale images of handwritten digits: 60000 images for training and 10000 for testing.\n",
    "\n",
    "It is included in the `mnist.tgz` archive provided with this TP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "8e1e3e19-c599-4633-b815-a5af3afe1cdb",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ef0c69a8ba2ce881cb101b8a63d2ef5f",
     "grade": false,
     "grade_id": "cell-5562efce16521bb8",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mnist-test-images.npy\n",
      "mnist-test-labels.npy\n",
      "mnist-train-images.npy\n",
      "mnist-train-labels.npy\n"
     ]
    }
   ],
   "source": [
    "!tar xvzf ./mnist.tgz\n",
    "images_train = np.load('./mnist-train-images.npy')\n",
    "labels_train = np.load('./mnist-train-labels.npy')\n",
    "images_test = np.load('./mnist-test-images.npy')\n",
    "labels_test = np.load('./mnist-test-labels.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60674f9f-1b2d-481c-8d9f-6427ea608d93",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "4acf046d404e63e8f9cf998a58328f22",
     "grade": false,
     "grade_id": "cell-c3a9fec3fa080314",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "**(Question)** Reshape the images into vectors and normalize the pixel values between 0 and 1. Convert the labels into one-hot vectors (*i.e.* vectors full of 0 and with only a 1 for the corresponding class). Store the results into `X_train`, `y_train`, `X_test` and `y_test` variables. Make sure to reshape to the following:\n",
    "- Input data: `n_features x n_samples`\n",
    "- Labels: `n_classes x n_samples`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "84e60aea-3db1-4bb2-a394-ce7f51ac3ca8",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "71b3aa5261b79b669d6a76c5634840a7",
     "grade": false,
     "grade_id": "cell-458517fdffea414b",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train = images_train.reshape((images_train.shape[0], (images_train.shape[1]*images_train.shape[2])))\n",
    "X_test = images_test.reshape((images_test.shape[0], (images_test.shape[1]*images_test.shape[2])))\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "n_classes = 10\n",
    "def arr_one(index):\n",
    "    arr = np.zeros(n_classes)\n",
    "    arr[index] = 1\n",
    "    return arr\n",
    "y_train = np.array([arr_one(ind) for ind in labels_train]).T\n",
    "y_test = np.array([arr_one(ind) for ind in labels_test]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "b753e345-4d69-47d3-bc2d-4a05f4c09766",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "978093784e5ba013a3a0636d87082cf1",
     "grade": true,
     "grade_id": "mnist-dataset",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "assert np.all(X_train >= 0.) and np.all(X_train <= 1.)\n",
    "assert np.all(X_test >= 0.) and np.all(X_test <= 1.)\n",
    "assert np.all(np.unique(y_train) == np.array([0., 1.])) \n",
    "assert np.all(np.unique(y_test) == np.array([0., 1.]))\n",
    "assert np.all(np.sum(y_train, axis=0) == 1.)\n",
    "assert np.all(np.sum(y_test, axis=0) == 1.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4c092ea-0342-4d64-89b9-c8ed5a1a2ad4",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "dd5c0f6c9bd960d9ea0b3cc726d41e90",
     "grade": false,
     "grade_id": "cell-6c0d93b6eb6561df",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "**(Question)** Initialize a neural network for MNIST with 32 hidden units and train it for 10 epochs with a batch size of 512."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77f0664e-95cb-4b4f-a711-ca5d7b067df2",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c48d1d1654c955db7f9263ad1c5abc6f",
     "grade": false,
     "grade_id": "cell-3cc325c6ca9e4632",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f971d1f-a2be-4e14-8b32-d16cf95133bb",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "0702549a613d49feff7dfd5b4178c833",
     "grade": false,
     "grade_id": "cell-c428e777c7ce4fc2",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "**(Question)** Compute the classification accuracy on the train and test sets. To do that, you can use the predict function and compare them with the original labels (*i.e.* without one-hot encoding)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0079310-dc37-4e09-a3d8-802d20f5c9ca",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9618f35d173603514e09391c99928a38",
     "grade": false,
     "grade_id": "cell-7b50de5211771a12",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f6902cd-b387-4a8a-a984-fd814651bcf2",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "df410b8867bd826543e85965cad6cdab",
     "grade": true,
     "grade_id": "accuracy",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "assert(0. <= accuracy_train <= 1.)\n",
    "assert(0. <= accuracy_test <= 1.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dea0b13d-ff16-4a77-b031-d6b770d8d542",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f1460ad42591ceee6c3ad8d6cd56e8f2",
     "grade": false,
     "grade_id": "cell-d57ca20154998a71",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "**(Question)** Compute and plot the confusion matrix for the test set. Which are the most difficult classes? Show some examples of misclassified images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd429c3b-0caa-4404-abd1-90634a141887",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "51b132b4eceadd782d22bae82c25bc98",
     "grade": false,
     "grade_id": "cell-a412a782fabb39c4",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65e2034c-1258-4e01-945f-6f1b5907dd7c",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "68541cac2f30c21ce5fa54188105962c",
     "grade": false,
     "grade_id": "cell-7d1885888535c8ea",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "**(Question)** Play around with hyperparameters of the model. What happens when the batch size if very small? And very large?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dd58d50-39f8-401b-b84e-b3cf5c060cf6",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a262e4a7afc1871ac16225f72c9bc7b7",
     "grade": true,
     "grade_id": "cell-b6db4b1e04482447",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75d5c9c3-b3fc-424c-b815-83c47a704229",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "143b011e40fc3c36f3d281586f34ba00",
     "grade": true,
     "grade_id": "cell-dd69c2dd2d0a35d2",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fccc60a-4f7d-4e31-827f-39b2791c1713",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "585921652da5e2beb11f7aca9c9721b0",
     "grade": false,
     "grade_id": "cell-60e9495352b554be",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "### 9. (BONUS) Extension to softmax and categorical cross-entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19d36216-95f5-4db1-b83d-39942e09df34",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b0e7cadb0c018a18655fd2664c7057b5",
     "grade": false,
     "grade_id": "cell-de5dfffbcb5a2be4",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": true
    },
    "tags": []
   },
   "source": [
    "**(Question)** Extend your neural network model to use a softmax activation function for the output layer, and a categorical cross-entropy loss.\n",
    "You can also experiment with the reLU activation for the hidden layer.\n",
    "\n",
    "*Hint:* recall the partial derivatives formulation from logistic regression, and optimize the backpropagation for the output layer accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96c24019-4f36-497f-ad3e-a42ce1a8ad79",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "79f9f104-9ab8-46f1-97a3-93b714e6b018",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "da3e081a9f0624df3655ec5890bebb82",
     "grade": false,
     "grade_id": "cell-4dccedea9995943c",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": true
    },
    "tags": []
   },
   "source": [
    "**(Question)** Extend your neural network model to handle more than one hidden layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7557a958-dbdb-44cd-9063-d22b68d3d9fd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
